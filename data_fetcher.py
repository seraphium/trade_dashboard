"""
IBKR Flex API æ•°æ®è·å–æ¨¡å—
"""
from ibflex import client, parser
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
import logging
from typing import Optional, Dict, Any
import yaml
import os
import re
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def safe_get_attr(obj, attr_name, default=None):
    """å®‰å…¨è·å–å¯¹è±¡å±æ€§ï¼Œæ”¯æŒå¤šç§è®¿é—®æ–¹å¼"""
    try:
        # æ–¹å¼1: ç›´æ¥getattr
        return getattr(obj, attr_name, default)
    except:
        try:
            # æ–¹å¼2: å¦‚æœå¯¹è±¡æœ‰__dict__
            if hasattr(obj, '__dict__'):
                return obj.__dict__.get(attr_name, default)
        except:
            try:
                # æ–¹å¼3: å¦‚æœå¯¹è±¡æ˜¯å­—å…¸å½¢å¼
                if hasattr(obj, '__getitem__'):
                    return obj[attr_name] if attr_name in obj else default
            except:
                pass
    return default


def safe_float(value, default=0.0):
    """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œå¤„ç†Noneå’Œæ— æ•ˆå€¼"""
    if value is None:
        return default
    try:
        return float(value)
    except (ValueError, TypeError):
        return default


# IBKR XML ä¸­å¯èƒ½å¯¼è‡´è§£æé—®é¢˜çš„å±æ€§åˆ—è¡¨
# è¿™äº›å±æ€§åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¯¼è‡´ ibflex è§£æå™¨å¤±è´¥ï¼Œéœ€è¦åœ¨é¢„å¤„ç†æ—¶ç§»é™¤
PROBLEMATIC_ATTRS = [
    # åŸºç¡€æ ‡è¯†ç¬¦å±æ€§
    'subCategory', 'underlyingConid', 'underlyingSymbol', 
    'underlyingSecurityID', 'underlyingListingExchange',
    'issuer', 'issuerCountryCode', 'securityIDType',
    'cusip', 'isin', 'figi', 'principalAdjustFactor',
    
    # äº¤æ˜“ç›¸å…³å±æ€§
    'relatedTradeID', 'strike', 'expiry', 'putCall',
    'settleDateTarget', 'tradeMoney',
    'netCash', 'closePrice', 'openCloseIndicator',
    'notes', 'cost', 'fifoPnlRealized', 'mtmPnl',
    
    # è®¢å•å’Œäº¤æ˜“IDå±æ€§
    'origTradePrice', 'origTradeDate', 'origTradeID',
    'origOrderID', 'origTransactionID', 'clearingFirmID',
    'ibExecID', 'relatedTransactionID', 'rtn',
    'brokerageOrderID', 'orderReference', 'volatilityOrderLink',
    'exchOrderId', 'extExecID', 'orderTime', 'openDateTime',
    
    # æ—¶é—´å’ŒçŠ¶æ€å±æ€§
    'holdingPeriodDateTime', 'whenRealized', 'whenReopened',
    'levelOfDetail', 'changeInPrice', 'changeInQuantity',
    'orderType', 'traderID', 'isAPIOrder', 'accruedInt',
    
    # äº¤æ˜“æ•°æ®å±æ€§ï¼ˆåœ¨æŸäº›æŸ¥è¯¢ç±»å‹ä¸­å¯èƒ½æœ‰é—®é¢˜ï¼‰
    'tradeID', 'tradePrice',
    'proceeds', 'commission', 'buySell',
    
    # å•†å“å’ŒæŠ•èµ„å±æ€§
    'initialInvestment', 'serialNumber', 'deliveryType',
    'commodityType', 'fineness', 'weight'
]

class IBKRDataFetcher:
    """IBKR Flex API æ•°æ®è·å–å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        # åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        load_dotenv()
        
        # å°è¯•ä» config.yaml åŠ è½½é…ç½®
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        except FileNotFoundError:
            self.config = {}
        
        # ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > .env æ–‡ä»¶ > config.yaml > é»˜è®¤å€¼
        self.flex_token = (
            os.getenv('IBKR_FLEX_TOKEN') or  # ç¯å¢ƒå˜é‡
            self.config.get('ibkr', {}).get('flex_token', '')  # config.yaml
        )
        
        # æ”¯æŒä¸¤ä¸ªä¸åŒçš„Query ID
        self.trades_query_id = (
            os.getenv('IBKR_TRADES_QUERY_ID') or  # ç¯å¢ƒå˜é‡
            self.config.get('ibkr', {}).get('trades_query_id', '') or  # config.yamlæ–°æ ¼å¼
            self.config.get('ibkr', {}).get('query_id', '')  # config.yamlæ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        )
        
        self.performance_query_id = (
            os.getenv('IBKR_PERFORMANCE_QUERY_ID') or  # ç¯å¢ƒå˜é‡
            self.config.get('ibkr', {}).get('performance_query_id', '')  # config.yamlæ–°æ ¼å¼
        )
    
    def validate_config(self, query_type: str = 'trades') -> bool:
        """
        éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´
        
        Args:
            query_type: æŸ¥è¯¢ç±»å‹ï¼Œ'trades' æˆ– 'performance' æˆ– 'all'
        """
        if not self.flex_token:
            return False
            
        if query_type == 'trades':
            return bool(self.trades_query_id)
        elif query_type == 'performance':
            return bool(self.performance_query_id)
        elif query_type == 'all':
            return bool(self.trades_query_id and self.performance_query_id)
        else:
            # é»˜è®¤æ£€æŸ¥trades query
            return bool(self.trades_query_id)
    
    def _download_with_retry(self, token: str, query_id: str, max_retries: int = 3, delay: float = 2.0):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®ä¸‹è½½
        
        Args:
            token: Flex Token
            query_id: Query ID  
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            delay: é‡è¯•é—´éš”(ç§’)
            
        Returns:
            APIå“åº”æ•°æ®
        """
        import time
        import ssl
        import urllib3
        from urllib3.exceptions import SSLError as Urllib3SSLError
        
        last_error = None
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    logger.info(f"é‡è¯•è·å–æ•°æ®ï¼Œç¬¬ {attempt}/{max_retries} æ¬¡")
                    time.sleep(delay * attempt)  # é€’å¢å»¶æ—¶
                
                # ä½¿ç”¨ ibflex åº“è·å–æ•°æ®
                response = client.download(token, query_id)
                logger.info("æ•°æ®è·å–æˆåŠŸ")
                return response
                
            except Exception as e:
                last_error = e
                error_str = str(e).lower()
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºç½‘ç»œç›¸å…³é”™è¯¯ï¼Œå€¼å¾—é‡è¯•
                is_retryable = any([
                    "ssl" in error_str,
                    "eof occurred" in error_str,
                    "connection" in error_str,
                    "timeout" in error_str,
                    "network" in error_str,
                    "max retries exceeded" in error_str
                ])
                
                if not is_retryable or attempt >= max_retries:
                    # ä¸å¯é‡è¯•çš„é”™è¯¯æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                    logger.error(f"è·å–æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {str(e)}")
                    raise e
                else:
                    logger.warning(f"ç½‘ç»œé”™è¯¯ï¼Œå°†é‡è¯• (å°è¯• {attempt + 1}/{max_retries + 1}): {str(e)}")
                    
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        raise last_error if last_error else Exception("æœªçŸ¥é”™è¯¯")
    
    @st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
    def fetch_trades(_self, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        è·å–äº¤æ˜“æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            DataFrame: äº¤æ˜“æ•°æ®
        """
        if not _self.validate_config('trades'):
            st.error("âŒ è¯·å…ˆåœ¨ config.yaml ä¸­é…ç½®æ‚¨çš„ IBKR Flex Token å’Œ Trades Query ID")
            return pd.DataFrame()
        
        try:
            logger.info(f"æ­£åœ¨è·å–äº¤æ˜“æ•°æ®: {start_date} åˆ° {end_date}")
            logger.info(f"ä½¿ç”¨ Token: {_self.flex_token[:10]}... å’Œ Trades Query ID: {_self.trades_query_id}")
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è·å–æ•°æ®
            response = _self._download_with_retry(_self.flex_token, _self.trades_query_id)
            
            # å°è¯•è§£ææ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™è¿›è¡Œé¢„å¤„ç†
            try:
                trades_data = parser.parse(response)
            except Exception as parse_error:
                logger.warning(f"åˆå§‹è§£æå¤±è´¥: {parse_error}")
                logger.info("å°è¯•é¢„å¤„ç† XML æ•°æ®...")
                
                # é¢„å¤„ç† XML æ•°æ®ï¼Œç§»é™¤å¯èƒ½æœ‰é—®é¢˜çš„å±æ€§
                xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                
                # ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„å±æ€§
                for attr in PROBLEMATIC_ATTRS:
                    # ç§»é™¤å±æ€§ï¼Œä½†ä¿ç•™æ ¸å¿ƒäº¤æ˜“æ•°æ®
                    pattern = f' {attr}="[^"]*"'
                    xml_str = re.sub(pattern, '', xml_str)
                
                # é‡æ–°å°è¯•è§£æ
                trades_data = parser.parse(xml_str.encode('utf-8'))
                logger.info("é¢„å¤„ç†åè§£ææˆåŠŸ")
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            if not hasattr(trades_data, 'FlexStatements') or not trades_data.FlexStatements:
                logger.warning("æœªæ‰¾åˆ° FlexStatements")
                st.warning("âš ï¸ API å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æ•°æ®è¯­å¥")
                return pd.DataFrame()
            
            # è·å–ç¬¬ä¸€ä¸ªè¯­å¥
            stmt = trades_data.FlexStatements[0]
            
            # å¦‚æœæ²¡æœ‰äº¤æ˜“æ•°æ®
            if not hasattr(stmt, 'Trades') or not stmt.Trades:
                logger.warning("æœªæ‰¾åˆ°äº¤æ˜“æ•°æ®")
                st.warning("âš ï¸ åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æœªæ‰¾åˆ°äº¤æ˜“è®°å½•")
                return pd.DataFrame()
            
            # è½¬æ¢ä¸º DataFrame
            trades_list = []
            for trade in stmt.Trades:
                # å®‰å…¨åœ°è·å–å±æ€§å€¼
                trade_id = str(getattr(trade, 'tradeID', ''))
                trade_date = getattr(trade, 'tradeDate', None)
                trade_time = getattr(trade, 'tradeTime', None)
                symbol = str(getattr(trade, 'symbol', ''))
                quantity = getattr(trade, 'quantity', 0)
                trade_price = getattr(trade, 'tradePrice', 0)
                currency = str(getattr(trade, 'currency', 'USD'))
                exchange = str(getattr(trade, 'exchange', ''))
                
                # å¤„ç†ä¹°å–æ–¹å‘
                buy_sell = getattr(trade, 'buySell', None)
                if buy_sell and hasattr(buy_sell, 'name'):
                    side = buy_sell.name  # 'BUY' æˆ– 'SELL'
                else:
                    # åå¤‡æ–¹æ¡ˆï¼šæ ¹æ®æ•°é‡æ­£è´Ÿåˆ¤æ–­
                    side = 'BUY' if float(quantity) > 0 else 'SELL'
                
                # åˆ›å»ºæ—¥æœŸæ—¶é—´
                datetime_str = None
                if trade_date and trade_time:
                    datetime_str = pd.to_datetime(f"{trade_date} {trade_time}")
                elif trade_date:
                    datetime_str = pd.to_datetime(str(trade_date))
                
                # å¤„ç†æ•°å€¼ç±»å‹ï¼ˆå¯èƒ½æ˜¯ Decimalï¼‰
                quantity_float = abs(safe_float(quantity))
                price_float = safe_float(trade_price)
                proceeds_float = safe_float(getattr(trade, 'proceeds', 0))
                commission_float = safe_float(getattr(trade, 'ibCommission', 0))
                
                trade_dict = {
                    'trade_id': trade_id,
                    'datetime': datetime_str,
                    'symbol': symbol,
                    'side': side,
                    'quantity': quantity_float,
                    'price': price_float,
                    'proceeds': proceeds_float,
                    'commission': commission_float,
                    'currency': currency,
                    'exchange': exchange,
                    'order_time': None,  # å…ˆç®€åŒ–ï¼Œå¯ä»¥åç»­æ·»åŠ 
                    'comment': ''  # åˆå§‹åŒ–è¯„è®ºåˆ—
                }
                trades_list.append(trade_dict)
            
            df = pd.DataFrame(trades_list)
            
            # æŒ‰æ—¶é—´è¿‡æ»¤
            if start_date:
                df = df[df['datetime'] >= pd.to_datetime(start_date)]
            if end_date:
                df = df[df['datetime'] <= pd.to_datetime(end_date)]
            
            # æ’åº
            df = df.sort_values('datetime', ascending=False)
            
            logger.info(f"æˆåŠŸè·å– {len(df)} æ¡äº¤æ˜“è®°å½•")
            return df
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"è·å–äº¤æ˜“æ•°æ®å¤±è´¥: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯åˆ†æå’Œè§£å†³å»ºè®®
            _self._show_detailed_error(error_msg)
            return pd.DataFrame()
    
    def _show_detailed_error(self, error_msg: str):
        """æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®"""
        st.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {error_msg}")
        
        # åˆ†æé”™è¯¯ç±»å‹å¹¶æä¾›å»ºè®®
        if "1020" in error_msg or "Invalid request" in error_msg:
            st.error("ğŸš¨ **é”™è¯¯ä»£ç  1020: è¯·æ±‚éªŒè¯å¤±è´¥**")
            st.markdown("""
            **å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**
            
            1. **Flex Token æ— æ•ˆæˆ–è¿‡æœŸ**
               - æ£€æŸ¥ Token æ˜¯å¦æ­£ç¡®å¤åˆ¶ï¼ˆä¸è¦åŒ…å«ç©ºæ ¼ï¼‰
               - åœ¨ IBKR è´¦æˆ·ç®¡ç†ä¸­é‡æ–°ç”Ÿæˆ Token
            
            2. **Query ID é”™è¯¯**
               - ç¡®è®¤ Query ID æ˜¯å¦æ­£ç¡®
               - æ£€æŸ¥ Flex Query æ˜¯å¦ä¸º "Active" çŠ¶æ€
            
            3. **Token å’Œ Query ID ä¸åŒ¹é…**
               - ç¡®ä¿ Token å’Œ Query æ¥è‡ªåŒä¸€ä¸ªè´¦æˆ·
               - æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„è´¦æˆ·é…ç½®
            
            4. **Flex Query é…ç½®é—®é¢˜**
               - ç¡®è®¤ Query ç±»å‹ä¸º "Activity Flex Query"
               - ç¡®è®¤å·²å‹¾é€‰ "Trades" æ•°æ®éƒ¨åˆ†
               - æ£€æŸ¥ Query çš„æ—¥æœŸèŒƒå›´è®¾ç½®
            """)
            
            # æä¾›è¯Šæ–­æŒ‰é’®
            if st.button("ğŸ” è¿è¡Œè¯Šæ–­æµ‹è¯•"):
                self._run_diagnostics()
                
        elif "network" in error_msg.lower() or "connection" in error_msg.lower() or "SSL" in error_msg or "EOF occurred" in error_msg:
            st.error("ğŸŒ **ç½‘ç»œè¿æ¥é—®é¢˜**")
            st.markdown("""
            **SSLè¿æ¥é—®é¢˜è§£å†³æ–¹æ¡ˆï¼š**
            
            1. **æ£€æŸ¥ç½‘ç»œè¿æ¥**
               - ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
               - å°è¯•åˆ·æ–°é¡µé¢é‡æ–°è·å–æ•°æ®
            
            2. **SSLåè®®é—®é¢˜**
               - è¿™æ˜¯IBKRæœåŠ¡å™¨SSLè¿æ¥ä¸­æ–­çš„å¸¸è§é—®é¢˜
               - é€šå¸¸æ˜¯æš‚æ—¶æ€§çš„ï¼Œè¯·ç¨ç­‰å‡ åˆ†é’Ÿåé‡è¯•
            
            3. **ä»£ç†æˆ–é˜²ç«å¢™**
               - å¦‚æœä½¿ç”¨å…¬å¸ç½‘ç»œï¼Œå¯èƒ½è¢«é˜²ç«å¢™é˜»æŒ¡
               - å°è¯•ä½¿ç”¨ä¸åŒçš„ç½‘ç»œç¯å¢ƒ
            
            4. **è¯·æ±‚é¢‘ç‡é™åˆ¶**
               - IBKRå¯èƒ½é™åˆ¶äº†è¯·æ±‚é¢‘ç‡
               - ç­‰å¾…1-2åˆ†é’Ÿåé‡æ–°å°è¯•
            """)
            
            # æä¾›é‡è¯•æŒ‰é’®
            if st.button("ğŸ”„ é‡æ–°å°è¯•è·å–æ•°æ®", key="retry_ssl"):
                st.rerun()
            
        else:
            st.error("â“ **æœªçŸ¥é”™è¯¯**")
            st.info("è¯·æ£€æŸ¥æ—¥å¿—è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯")
    
    def _run_diagnostics(self):
        """è¿è¡Œè¯Šæ–­æµ‹è¯•"""
        st.subheader("ğŸ” è¯Šæ–­æµ‹è¯•ç»“æœ")
        
        # 1. é…ç½®æ£€æŸ¥
        with st.expander("1. é…ç½®æ£€æŸ¥", expanded=True):
            if self.flex_token:
                st.success(f"âœ… Flex Token: {self.flex_token[:10]}...{self.flex_token[-4:]}")
            else:
                st.error("âŒ Flex Token æœªé…ç½®")
            
            if self.query_id:
                st.success(f"âœ… Query ID: {self.query_id}")
            else:
                st.error("âŒ Query ID æœªé…ç½®")
        
        # 2. è¿æ¥æµ‹è¯•
        with st.expander("2. API è¿æ¥æµ‹è¯•", expanded=True):
            if self.validate_config():
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    try:
                        response = self._download_with_retry(self.flex_token, self.query_id)
                        st.success("âœ… API è¿æ¥æˆåŠŸ")
                        
                        try:
                            data = parser.parse(response)
                            st.success("âœ… æ•°æ®è§£ææˆåŠŸ")
                        except Exception as parse_error:
                            st.warning(f"âš ï¸ åˆå§‹è§£æå¤±è´¥: {parse_error}")
                            st.info("æ­£åœ¨å°è¯•é¢„å¤„ç†æ•°æ®...")
                            
                            # é¢„å¤„ç† XML æ•°æ®
                            xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                            
                            # ä½¿ç”¨å®Œæ•´çš„å±æ€§æ¸…ç†åˆ—è¡¨
                            for attr in PROBLEMATIC_ATTRS:
                                pattern = f' {attr}="[^"]*"'
                                xml_str = re.sub(pattern, '', xml_str)
                            
                            data = parser.parse(xml_str.encode('utf-8'))
                            st.success("âœ… é¢„å¤„ç†åè§£ææˆåŠŸ")
                        
                        # æ£€æŸ¥æ•°æ®å†…å®¹
                        if hasattr(data, 'FlexStatements') and data.FlexStatements:
                            stmt = data.FlexStatements[0]
                            if hasattr(stmt, 'Trades') and stmt.Trades:
                                st.success(f"âœ… æ‰¾åˆ° {len(stmt.Trades)} æ¡äº¤æ˜“è®°å½•")
                            else:
                                st.warning("âš ï¸ æœªæ‰¾åˆ°äº¤æ˜“è®°å½•ï¼ˆå¯èƒ½æ˜¯æ—¥æœŸèŒƒå›´é—®é¢˜ï¼‰")
                        else:
                            st.warning("âš ï¸ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ° FlexStatements")
                            
                    except Exception as conn_error:
                        st.error(f"âŒ è¿æ¥å¤±è´¥: {conn_error}")
                        
                        # æä¾›å…·ä½“çš„é”™è¯¯è§£å†³å»ºè®®
                        error_str = str(conn_error)
                        if "1020" in error_str:
                            st.markdown("""
                            **é”™è¯¯ 1020 è§£å†³æ­¥éª¤ï¼š**
                            1. ç™»å½• IBKR è´¦æˆ·ç®¡ç†
                            2. æ£€æŸ¥ Flex Query çŠ¶æ€æ˜¯å¦ä¸º "Active"
                            3. é‡æ–°ç”Ÿæˆ Flex Token
                            4. ç¡®è®¤ Query åŒ…å« "Trades" æ•°æ®
                            """)
            else:
                st.error("âŒ é…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•è¿›è¡Œè¿æ¥æµ‹è¯•")
    
    def get_account_summary(self) -> Dict[str, Any]:
        """è·å–è´¦æˆ·æ¦‚è¦ä¿¡æ¯"""
        try:
            # ä¼˜å…ˆä½¿ç”¨performance queryï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨trades query
            query_id = self.performance_query_id or self.trades_query_id
            if not query_id:
                logger.error("æœªé…ç½®ä»»ä½•Query ID")
                return {}
            
            response = self._download_with_retry(self.flex_token, query_id)
            
            try:
                data = parser.parse(response)
            except Exception as parse_error:
                logger.warning(f"è´¦æˆ·ä¿¡æ¯è§£æå¤±è´¥ï¼Œå°è¯•é¢„å¤„ç†: {parse_error}")
                
                # é¢„å¤„ç† XML æ•°æ®
                xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                
                # ä½¿ç”¨å®Œæ•´çš„å±æ€§æ¸…ç†åˆ—è¡¨
                for attr in PROBLEMATIC_ATTRS:
                    pattern = f' {attr}="[^"]*"'
                    xml_str = re.sub(pattern, '', xml_str)
                
                data = parser.parse(xml_str.encode('utf-8'))
            
            summary = {}
            if hasattr(data, 'FlexStatements') and data.FlexStatements:
                stmt = data.FlexStatements[0]
                if hasattr(stmt, 'AccountInformation') and stmt.AccountInformation:
                    account = stmt.AccountInformation[0]  # è·å–ç¬¬ä¸€ä¸ªè´¦æˆ·ä¿¡æ¯
                    summary['account_id'] = getattr(account, 'accountId', 'Unknown')
                    summary['base_currency'] = getattr(account, 'currency', 'USD')
                    summary['account_type'] = getattr(account, 'accountType', 'Unknown')
                    summary['last_traded_date'] = getattr(account, 'lastTradedDate', None)
                    summary['name'] = getattr(account, 'name', 'Unknown')
            
            return summary
        except Exception as e:
            logger.error(f"è·å–è´¦æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}

    @st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
    def fetch_nav_data(_self, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        è·å–æ¯æ—¥å‡€èµ„äº§ä»·å€¼(NAV)æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            DataFrame: NAVæ•°æ®ï¼ŒåŒ…å«æ—¥æœŸå’Œå‡€èµ„äº§ä»·å€¼
        """
        if not _self.validate_config('performance'):
            st.error("âŒ è¯·å…ˆé…ç½® IBKR Performance Query ID")
            return pd.DataFrame()
        
        try:
            logger.info(f"æ­£åœ¨è·å–NAVæ•°æ®: {start_date} åˆ° {end_date}")
            logger.info(f"ä½¿ç”¨ Performance Query ID: {_self.performance_query_id}")
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶è·å–æ•°æ®
            response = _self._download_with_retry(_self.flex_token, _self.performance_query_id)
            
            # è§£ææ•°æ®
            try:
                nav_data = parser.parse(response)
            except Exception as parse_error:
                logger.warning(f"NAVæ•°æ®è§£æå¤±è´¥ï¼Œå°è¯•é¢„å¤„ç†: {parse_error}")
                
                # é¢„å¤„ç† XML æ•°æ®
                xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                
                # ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„å±æ€§ - ä½†ä¿ç•™é‡è¦çš„æ€§èƒ½æ•°æ®å±æ€§
                # æ³¨æ„ï¼šPROBLEMATIC_ATTRS åŒ…å«äº† dateTimeï¼Œä½†æˆ‘ä»¬å¯èƒ½éœ€è¦ä¿ç•™å®ƒç”¨äºæŸäº›æ€§èƒ½æ•°æ®
                # ä¸ç§»é™¤: currency, reportDate, stock, options ç­‰é‡è¦å±æ€§
                for attr in PROBLEMATIC_ATTRS:
                    pattern = f' {attr}="[^"]*"'
                    xml_str = re.sub(pattern, '', xml_str)
                
                try:
                    nav_data = parser.parse(xml_str.encode('utf-8'))
                    logger.info("XMLé¢„å¤„ç†åè§£ææˆåŠŸ")
                except Exception as final_error:
                    logger.error(f"é¢„å¤„ç†åä»ç„¶è§£æå¤±è´¥: {final_error}")
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œç›´æ¥è¿”å›ç©ºæ•°æ®
                    return pd.DataFrame()
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            if not hasattr(nav_data, 'FlexStatements') or not nav_data.FlexStatements:
                logger.warning("æœªæ‰¾åˆ° FlexStatements")
                return pd.DataFrame()
            
            stmt = nav_data.FlexStatements[0]
            
            # æŸ¥æ‰¾NAVæ•°æ®ï¼ˆå¯èƒ½åœ¨ä¸åŒèŠ‚ç‚¹ä¸­ï¼‰
            nav_list = []
            
            # æ£€æŸ¥ NetAssetValue èŠ‚ç‚¹
            if hasattr(stmt, 'NetAssetValue') and stmt.NetAssetValue:
                for nav_item in stmt.NetAssetValue:
                    nav_dict = {
                        'reportDate': safe_get_attr(nav_item, 'reportDate', None),
                        'total': safe_get_attr(nav_item, 'total', 0),
                        'currency': safe_get_attr(nav_item, 'currency', 'USD')
                    }
                    nav_list.append(nav_dict)
            
            # æ£€æŸ¥ EquitySummaryInBase èŠ‚ç‚¹ï¼ˆç”¨æˆ·æ•°æ®æ ¼å¼ï¼‰
            elif hasattr(stmt, 'EquitySummaryInBase') and stmt.EquitySummaryInBase:
                logger.info("ä» EquitySummaryInBase èŠ‚ç‚¹è·å–NAVæ•°æ®")
                for equity_item in stmt.EquitySummaryInBase:
                    try:
                        # å®‰å…¨è·å–å„å±æ€§
                        stock_value = safe_float(safe_get_attr(equity_item, 'stock', 0))
                        options_value = safe_float(safe_get_attr(equity_item, 'options', 0))
                        total_nav = stock_value + options_value
                        
                        nav_dict = {
                            'reportDate': safe_get_attr(equity_item, 'reportDate', None),
                            'total': total_nav,
                            'currency': safe_get_attr(equity_item, 'currency', 'USD'),
                            'stock': stock_value,
                            'options': options_value
                        }
                        
                        logger.debug(f"å¤„ç†NAVè®°å½•: {nav_dict}")
                        nav_list.append(nav_dict)
                        
                    except Exception as item_error:
                        logger.warning(f"å¤„ç†å•ä¸ªNAVè®°å½•å¤±è´¥: {item_error}")
                        # è®°å½•å¯ç”¨çš„å±æ€§ä»¥ä¾¿è°ƒè¯•
                        available_attrs = [attr for attr in dir(equity_item) if not attr.startswith('_')]
                        logger.debug(f"å¯¹è±¡å¯ç”¨å±æ€§: {available_attrs}")
                        continue
            
            # æ£€æŸ¥ EquitySummaryByReportDateInBase èŠ‚ç‚¹ï¼ˆperformance queryæ ¼å¼ï¼‰
            elif hasattr(stmt, 'EquitySummaryByReportDateInBase') and stmt.EquitySummaryByReportDateInBase:
                logger.info("ä» EquitySummaryByReportDateInBase èŠ‚ç‚¹è·å–NAVæ•°æ®")
                for equity_item in stmt.EquitySummaryByReportDateInBase:
                    try:
                        # å®‰å…¨è·å–å„å±æ€§
                        stock_value = safe_float(safe_get_attr(equity_item, 'stock', 0))
                        options_value = safe_float(safe_get_attr(equity_item, 'options', 0))
                        total_nav = stock_value + options_value
                        
                        nav_dict = {
                            'reportDate': safe_get_attr(equity_item, 'reportDate', None),
                            'total': total_nav,
                            'currency': safe_get_attr(equity_item, 'currency', 'USD'),
                            'stock': stock_value,
                            'options': options_value
                        }
                        
                        logger.debug(f"å¤„ç†NAVè®°å½•: {nav_dict}")
                        nav_list.append(nav_dict)
                        
                    except Exception as item_error:
                        logger.warning(f"å¤„ç†å•ä¸ªNAVè®°å½•å¤±è´¥: {item_error}")
                        # è®°å½•å¯ç”¨çš„å±æ€§ä»¥ä¾¿è°ƒè¯•
                        available_attrs = [attr for attr in dir(equity_item) if not attr.startswith('_')]
                        logger.debug(f"å¯¹è±¡å¯ç”¨å±æ€§: {available_attrs}")
                        continue
            
            # æ£€æŸ¥ MTMPerformanceSummaryInBase èŠ‚ç‚¹ï¼ˆæ€§èƒ½æ€»ç»“æ•°æ®ï¼‰
            elif hasattr(stmt, 'MTMPerformanceSummaryInBase') and stmt.MTMPerformanceSummaryInBase:
                logger.info("ä» MTMPerformanceSummaryInBase èŠ‚ç‚¹è·å–NAVæ•°æ®")
                for mtm_item in stmt.MTMPerformanceSummaryInBase:
                    try:
                        # ä»MTMæ•°æ®æ¨å¯¼NAV
                        ending_value = safe_float(safe_get_attr(mtm_item, 'endingValue', 0))
                        
                        nav_dict = {
                            'reportDate': safe_get_attr(mtm_item, 'reportDate', None),
                            'total': ending_value,
                            'currency': safe_get_attr(mtm_item, 'currency', 'USD'),
                            'stock': ending_value,  # ç®€åŒ–å¤„ç†
                            'options': 0
                        }
                        
                        logger.debug(f"å¤„ç†MTM NAVè®°å½•: {nav_dict}")
                        nav_list.append(nav_dict)
                        
                    except Exception as item_error:
                        logger.warning(f"å¤„ç†å•ä¸ªMTMè®°å½•å¤±è´¥: {item_error}")
                        # è®°å½•å¯ç”¨çš„å±æ€§ä»¥ä¾¿è°ƒè¯•
                        available_attrs = [attr for attr in dir(mtm_item) if not attr.startswith('_')]
                        logger.debug(f"MTMå¯¹è±¡å¯ç”¨å±æ€§: {available_attrs}")
                        continue
            
            # å¦‚æœæ²¡æœ‰ä¸“é—¨çš„NAVæ•°æ®ï¼Œå°è¯•ä»å…¶ä»–èŠ‚ç‚¹æ¨å¯¼
            elif hasattr(stmt, 'Trades') or hasattr(stmt, 'CashTransactions'):
                # å¯ä»¥ä»æŒä»“å’Œç°é‡‘æ•°æ®è®¡ç®—NAVï¼Œè¿™é‡Œå…ˆè¿”å›ç©ºæ•°æ®
                logger.warning("æœªæ‰¾åˆ°ä¸“é—¨çš„NAVæ•°æ®ï¼Œéœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è®¡ç®—")
                return pd.DataFrame(columns=['reportDate', 'total', 'currency', 'stock', 'options'])
            
            if not nav_list:
                logger.warning("æœªæ‰¾åˆ°NAVæ•°æ®")
                return pd.DataFrame(columns=['reportDate', 'total', 'currency', 'stock', 'options'])
            
            df = pd.DataFrame(nav_list)
            
            # æ•°æ®æ¸…ç†
            df['reportDate'] = pd.to_datetime(df['reportDate'])
            df['total'] = pd.to_numeric(df['total'], errors='coerce')
            
            # æŒ‰æ—¶é—´è¿‡æ»¤
            if start_date:
                df = df[df['reportDate'] >= pd.to_datetime(start_date)]
            if end_date:
                df = df[df['reportDate'] <= pd.to_datetime(end_date)]
            
            # æ’åº
            df = df.sort_values('reportDate', ascending=True)
            
            logger.info(f"æˆåŠŸè·å– {len(df)} æ¡NAVè®°å½•")
            return df
            
        except Exception as e:
            logger.error(f"è·å–NAVæ•°æ®å¤±è´¥: {e}")
            st.error(f"âŒ è·å–NAVæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    @st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
    def fetch_cash_transactions(_self, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        è·å–ç°é‡‘æµæ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            DataFrame: ç°é‡‘æµæ•°æ®
        """
        if not _self.validate_config('performance'):
            st.error("âŒ è¯·å…ˆé…ç½® IBKR Performance Query ID")
            return pd.DataFrame()
        
        try:
            logger.info(f"æ­£åœ¨è·å–ç°é‡‘æµæ•°æ®: {start_date} åˆ° {end_date}")
            logger.info(f"ä½¿ç”¨ Performance Query ID: {_self.performance_query_id}")
            
            response = _self._download_with_retry(_self.flex_token, _self.performance_query_id)
            
            try:
                cash_data = parser.parse(response)
            except Exception as parse_error:
                logger.warning(f"ç°é‡‘æµæ•°æ®è§£æå¤±è´¥ï¼Œå°è¯•é¢„å¤„ç†: {parse_error}")
                
                xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                
                # ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„å±æ€§ - ä½†ä¿ç•™ç°é‡‘æµç›¸å…³çš„é‡è¦å±æ€§
                # ä¿ç•™: currency, reportDate, amount, type, dateTime, activityDescriptionç­‰é‡è¦å±æ€§
                # ç§»é™¤XMLä¸­çš„æ¢è¡Œç¬¦
                xml_str = xml_str.replace('\n', '').replace('\r', '')
                for attr in PROBLEMATIC_ATTRS:
                    pattern = f' {attr}="[^"]*"'
                    xml_str = re.sub(pattern, '', xml_str)
                
                try:
                    cash_data = parser.parse(xml_str.encode('utf-8'))
                    logger.info("ç°é‡‘æµXMLé¢„å¤„ç†åè§£ææˆåŠŸ")
                except Exception as final_error:
                    logger.error(f"ç°é‡‘æµé¢„å¤„ç†åä»ç„¶è§£æå¤±è´¥: {final_error}")
                    return pd.DataFrame()
            
            if not hasattr(cash_data, 'FlexStatements') or not cash_data.FlexStatements:
                logger.warning("æœªæ‰¾åˆ° FlexStatements")
                return pd.DataFrame()
            
            stmt = cash_data.FlexStatements[0]
            
            cash_list = []
            
            # æ£€æŸ¥ CashTransactions èŠ‚ç‚¹
            if hasattr(stmt, 'CashTransactions') and stmt.CashTransactions:
                logger.info(f"æ‰¾åˆ° {len(stmt.CashTransactions)} æ¡ç°é‡‘æµè®°å½•")
                for cash_item in stmt.CashTransactions:
                    try:
                        report_date = safe_get_attr(cash_item, 'reportDate', None)
                        amount = safe_get_attr(cash_item, 'amount', 0)
                        cash_type = safe_get_attr(cash_item, 'type', '')
                        
                        # å¦‚æœæ²¡æœ‰dateTimeï¼Œä½¿ç”¨reportDate
                        date_time = safe_get_attr(cash_item, 'dateTime', None)
                        if not date_time and report_date:
                            date_time = report_date
                        
                        cash_dict = {
                            'reportDate': report_date,
                            'dateTime': date_time,
                            'amount': safe_float(amount),
                            'currency': safe_get_attr(cash_item, 'currency', 'USD'),
                            'type': cash_type,
                            'activityDescription': safe_get_attr(cash_item, 'activityDescription', cash_type),
                            'symbol': safe_get_attr(cash_item, 'symbol', ''),
                            'accountId': safe_get_attr(cash_item, 'accountId', ''),
                            'tradeID': safe_get_attr(cash_item, 'tradeID', '')
                        }
                        
                        logger.debug(f"å¤„ç†ç°é‡‘æµè®°å½•: {cash_dict}")
                        cash_list.append(cash_dict)
                        
                    except Exception as item_error:
                        logger.warning(f"å¤„ç†å•ä¸ªç°é‡‘æµè®°å½•å¤±è´¥: {item_error}")
                        # è®°å½•å¯ç”¨çš„å±æ€§ä»¥ä¾¿è°ƒè¯•
                        available_attrs = [attr for attr in dir(cash_item) if not attr.startswith('_')]
                        logger.debug(f"ç°é‡‘æµå¯¹è±¡å¯ç”¨å±æ€§: {available_attrs}")
                        continue
            
            if not cash_list:
                logger.warning("æœªæ‰¾åˆ°ç°é‡‘æµæ•°æ®")
                return pd.DataFrame(columns=['reportDate', 'dateTime', 'amount', 'currency', 'type', 'activityDescription', 'symbol', 'accountId', 'tradeID'])
            
            df = pd.DataFrame(cash_list)
            
            # æ•°æ®æ¸…ç†
            df['reportDate'] = pd.to_datetime(df['reportDate'], errors='coerce')
            df['dateTime'] = pd.to_datetime(df['dateTime'], errors='coerce')
            df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
            
            # æŒ‰æ—¶é—´è¿‡æ»¤
            if start_date:
                df = df[df['reportDate'] >= pd.to_datetime(start_date)]
            if end_date:
                df = df[df['reportDate'] <= pd.to_datetime(end_date)]
            
            # æ’åº
            df = df.sort_values('reportDate', ascending=True)
            
            logger.info(f"æˆåŠŸè·å– {len(df)} æ¡ç°é‡‘æµè®°å½•")
            return df
            
        except Exception as e:
            logger.error(f"è·å–ç°é‡‘æµæ•°æ®å¤±è´¥: {e}")
            st.error(f"âŒ è·å–ç°é‡‘æµæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    @st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶  
    def fetch_positions(_self, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """
        è·å–æŒä»“æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            DataFrame: æŒä»“æ•°æ®
        """
        if not _self.validate_config('performance'):
            st.error("âŒ è¯·å…ˆé…ç½® IBKR Performance Query ID")
            return pd.DataFrame()
        
        try:
            logger.info(f"æ­£åœ¨è·å–æŒä»“æ•°æ®: {start_date} åˆ° {end_date}")
            logger.info(f"ä½¿ç”¨ Performance Query ID: {_self.performance_query_id}")
            
            response = _self._download_with_retry(_self.flex_token, _self.performance_query_id)
            
            try:
                pos_data = parser.parse(response)
            except Exception as parse_error:
                logger.warning(f"æŒä»“æ•°æ®è§£æå¤±è´¥ï¼Œå°è¯•é¢„å¤„ç†: {parse_error}")
                
                xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                
                # ä½¿ç”¨ä¸NAVç›¸åŒçš„å®Œæ•´å±æ€§æ¸…ç†åˆ—è¡¨
                for attr in PROBLEMATIC_ATTRS:
                    pattern = f' {attr}="[^"]*"'
                    xml_str = re.sub(pattern, '', xml_str)
                
                pos_data = parser.parse(xml_str.encode('utf-8'))
            
            if not hasattr(pos_data, 'FlexStatements') or not pos_data.FlexStatements:
                logger.warning("æœªæ‰¾åˆ° FlexStatements")
                return pd.DataFrame()
            
            stmt = pos_data.FlexStatements[0]
            
            pos_list = []
            
            # æ£€æŸ¥ Positions èŠ‚ç‚¹
            if hasattr(stmt, 'Positions') and stmt.Positions:
                for pos_item in stmt.Positions:
                    pos_dict = {
                        'reportDate': safe_get_attr(pos_item, 'reportDate', None),
                        'symbol': safe_get_attr(pos_item, 'symbol', ''),
                        'position': safe_get_attr(pos_item, 'position', 0),
                        'markPrice': safe_get_attr(pos_item, 'markPrice', 0),
                        'positionValue': safe_get_attr(pos_item, 'positionValue', 0),
                        'currency': safe_get_attr(pos_item, 'currency', 'USD'),
                        'accountId': safe_get_attr(pos_item, 'accountId', ''),
                        'assetCategory': safe_get_attr(pos_item, 'assetCategory', '')
                    }
                    pos_list.append(pos_dict)
            
            if not pos_list:
                logger.warning("æœªæ‰¾åˆ°æŒä»“æ•°æ®")
                return pd.DataFrame(columns=['reportDate', 'symbol', 'position', 'markPrice', 'positionValue', 'currency'])
            
            df = pd.DataFrame(pos_list)
            
            # æ•°æ®æ¸…ç†
            df['reportDate'] = pd.to_datetime(df['reportDate'], errors='coerce')
            df['position'] = pd.to_numeric(df['position'], errors='coerce')
            df['markPrice'] = pd.to_numeric(df['markPrice'], errors='coerce')
            df['positionValue'] = pd.to_numeric(df['positionValue'], errors='coerce')
            
            # æŒ‰æ—¶é—´è¿‡æ»¤
            if start_date:
                df = df[df['reportDate'] >= pd.to_datetime(start_date)]
            if end_date:
                df = df[df['reportDate'] <= pd.to_datetime(end_date)]
            
            # æ’åº
            df = df.sort_values(['reportDate', 'symbol'], ascending=True)
            
            logger.info(f"æˆåŠŸè·å– {len(df)} æ¡æŒä»“è®°å½•")
            return df
            
        except Exception as e:
            logger.error(f"è·å–æŒä»“æ•°æ®å¤±è´¥: {e}")
            st.error(f"âŒ è·å–æŒä»“æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

def _download_with_global_retry(token: str, query_id: str, max_retries: int = 3, delay: float = 2.0):
    """
    å…¨å±€é‡è¯•ä¸‹è½½å‡½æ•°
    
    Args:
        token: Flex Token
        query_id: Query ID  
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: é‡è¯•é—´éš”(ç§’)
        
    Returns:
        APIå“åº”æ•°æ®
    """
    import time
    
    last_error = None
    
    for attempt in range(max_retries + 1):
        try:
            if attempt > 0:
                logger.info(f"é‡è¯•è·å–æ•°æ®ï¼Œç¬¬ {attempt}/{max_retries} æ¬¡")
                time.sleep(delay * attempt)  # é€’å¢å»¶æ—¶
            
            # ä½¿ç”¨ ibflex åº“è·å–æ•°æ®
            response = client.download(token, query_id)
            logger.info("æ•°æ®è·å–æˆåŠŸ")
            return response
            
        except Exception as e:
            last_error = e
            error_str = str(e).lower()
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºç½‘ç»œç›¸å…³é”™è¯¯ï¼Œå€¼å¾—é‡è¯•
            is_retryable = any([
                "ssl" in error_str,
                "eof occurred" in error_str,
                "connection" in error_str,
                "timeout" in error_str,
                "network" in error_str,
                "max retries exceeded" in error_str
            ])
            
            if not is_retryable or attempt >= max_retries:
                # ä¸å¯é‡è¯•çš„é”™è¯¯æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                logger.error(f"è·å–æ•°æ®å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {str(e)}")
                raise e
            else:
                logger.warning(f"ç½‘ç»œé”™è¯¯ï¼Œå°†é‡è¯• (å°è¯• {attempt + 1}/{max_retries + 1}): {str(e)}")
                
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
    raise last_error if last_error else Exception("æœªçŸ¥é”™è¯¯")

def test_connection(token: str, query_id: str) -> tuple[bool, str]:
    """
    æµ‹è¯• API è¿æ¥
    
    Returns:
        tuple: (æ˜¯å¦æˆåŠŸ, è¯¦ç»†ä¿¡æ¯)
    """
    try:
        if not token or not query_id:
            return False, "Token æˆ– Query ID æœªé…ç½®"
            
        logger.info(f"æµ‹è¯•è¿æ¥: Token={token[:10]}... Query ID={query_id}")
        response = _download_with_global_retry(token, query_id)
        
        try:
            data = parser.parse(response)
        except Exception as parse_error:
            logger.warning(f"åˆå§‹è§£æå¤±è´¥ï¼Œå°è¯•é¢„å¤„ç†: {parse_error}")
            
            # é¢„å¤„ç† XML æ•°æ®
            xml_str = response.decode('utf-8') if isinstance(response, bytes) else str(response)
                      
            for attr in PROBLEMATIC_ATTRS:
                pattern = f' {attr}="[^"]*"'
                xml_str = re.sub(pattern, '', xml_str)
            
            data = parser.parse(xml_str.encode('utf-8'))
        
        # æ£€æŸ¥å“åº”æ•°æ®å†…å®¹
        if hasattr(data, 'FlexStatements') and data.FlexStatements:
            stmt = data.FlexStatements[0]
            data_found = []
            
            # æ£€æŸ¥å„ç§æ•°æ®ç±»å‹
            if hasattr(stmt, 'Trades') and stmt.Trades:
                trade_count = len(stmt.Trades)
                data_found.append(f"{trade_count} æ¡äº¤æ˜“è®°å½•")
            
            if hasattr(stmt, 'EquitySummaryInBase') and stmt.EquitySummaryInBase:
                nav_count = len(stmt.EquitySummaryInBase)
                data_found.append(f"{nav_count} æ¡NAVè®°å½•")
            
            if hasattr(stmt, 'CashTransactions') and stmt.CashTransactions:
                cash_count = len(stmt.CashTransactions)
                data_found.append(f"{cash_count} æ¡ç°é‡‘æµè®°å½•")
            
            if hasattr(stmt, 'OpenPositions') and stmt.OpenPositions:
                pos_count = len(stmt.OpenPositions)
                data_found.append(f"{pos_count} æ¡æŒä»“è®°å½•")
            
            if hasattr(stmt, 'MTMPerformanceSummaryInBase') and stmt.MTMPerformanceSummaryInBase:
                mtm_count = len(stmt.MTMPerformanceSummaryInBase)
                data_found.append(f"{mtm_count} æ¡MTMè®°å½•")
            
            if data_found:
                return True, f"è¿æ¥æˆåŠŸï¼Œæ‰¾åˆ°: {', '.join(data_found)}"
            else:
                return True, "è¿æ¥æˆåŠŸï¼Œä½†æœªæ‰¾åˆ°é¢„æœŸçš„æ•°æ®éƒ¨åˆ†ï¼ˆè¯·æ£€æŸ¥ Flex Query é…ç½®ï¼‰"
        else:
            return True, "è¿æ¥æˆåŠŸï¼Œä½†å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ° FlexStatements"
            
    except Exception as e:
        error_msg = str(e)
        
        # åˆ†æå…·ä½“é”™è¯¯ç±»å‹
        if "1020" in error_msg:
            return False, "é”™è¯¯ 1020: Token æˆ– Query ID æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"
        elif "1003" in error_msg:
            return False, "é”™è¯¯ 1003: Query æœªæ¿€æ´»æˆ–ä¸å­˜åœ¨"
        elif "1019" in error_msg:
            return False, "é”™è¯¯ 1019: Token å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç”Ÿæˆ"
        elif "network" in error_msg.lower() or "timeout" in error_msg.lower():
            return False, f"ç½‘ç»œè¿æ¥é—®é¢˜: {error_msg}"
        else:
            return False, f"è¿æ¥å¤±è´¥: {error_msg}" 
